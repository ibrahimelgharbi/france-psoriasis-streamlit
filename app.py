import streamlit as st
import pandas as pd
import numpy as np
from scipy import stats
import plotly.express as px
from sklearn.cluster import KMeans

# Pillow pour les logos
try:
    from PIL import Image
except ImportError:
    Image = None

# ---------------------------------------------------------
# CONFIG G√âN√âRALE & THEME
# ---------------------------------------------------------
st.set_page_config(
    page_title="France Psoriasis ‚Äì Analyse",
    page_icon="logo_france_psoriasis.png",  # le fichier doit √™tre dans le m√™me dossier que app.py
    layout="wide"
)

# Th√®me clair + marge haute pour que le header ne soit pas coup√©
st.markdown(
    """
    <style>
    .stApp {
        background-color: #ffffff;
    }
    .block-container {
        padding-top: 2.5rem !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# Colonnes/Pr√©fixes √† exclure des analyses
EXCLUDE_PREFIXES = (
    "alerte", "alertes", "CW", "CW_", "CW_token", "CW_status",
    "CW_firstdate", "CW_firsttime", "CW_finishdate",
    "CW_finishtime"
)
EXCLUDE_COLUMNS = {"nbj", "vague", "fincontact", "mode", "revi"}

# Familles de questions multi-r√©ponses √† regrouper par texte
TARGET_MULTI_QIDS = {
    "rs7aa", "rs7ab", "rs7ba", "rs7bb",
    "a3", "b5", "b6", "b10",
    "recrs7aa", "recrs7", "recrs7a"
}

# ---------------------------------------------------------
# FONCTIONS UTILITAIRES
# ---------------------------------------------------------
def get_question_id(name: str) -> str:
    """
    Identifiant 'question' √† partir du Name du codebook.
    Exemples :
      - 'b6:1'       -> 'b6'
      - 'rs7ab_1:17' -> 'rs7ab'
    """
    s = str(name)
    if ":" in s:
        s = s.split(":", 1)[0]
    if "_" in s:
        s = s.split("_", 1)[0]
    return s


def app_header():
    """Affiche le bandeau sup√©rieur avec logos et cr√©dits."""
    col1, col2, col3 = st.columns([1, 2, 1])

    with col1:
        if Image is not None:
            try:
                img1 = Image.open("logo_france_psoriasis.png")
                st.image(img1, use_column_width=True)
            except Exception:
                st.markdown("**France Psoriasis**")
        else:
            st.markdown("**France Psoriasis**")

    with col3:
        if Image is not None:
            try:
                img2 = Image.open("logo_cha.png")
                st.image(img2, use_column_width=True)
            except Exception:
                st.markdown("**Centre Hospitalier d‚ÄôArgenteuil**")
        else:
            st.markdown("**Centre Hospitalier d‚ÄôArgenteuil**")

    with col2:
        st.markdown(
            """
            <div style="text-align:center;">
              <div style="font-size:22px; font-weight:bold; margin-bottom:4px;">
                Psoriasis
              </div>
              <div style="font-size:17px; margin-bottom:4px;">
                Centre Hospitalier d‚ÄôArgenteuil & Association France Psoriasis
              </div>
              <div style="font-size:14px; color:#555;">
                Site con√ßu par <b>Dr Dorra MEDHAFFAR</b> & <b>Pr Emmanuel Mah√©</b>
              </div>
            </div>
            """,
            unsafe_allow_html=True,
        )

    st.markdown("---")


@st.cache_data
def load_data():
    """Charge le fichier Excel BDD_pso.xlsx et pr√©pare Codebook + Data."""
    xls = pd.ExcelFile("BDD_pso.xlsx")
    sheetnames = {s.lower(): s for s in xls.sheet_names}

    if "codebook" not in sheetnames or "data" not in sheetnames:
        raise ValueError("Les onglets 'Codebook' et 'Data' sont requis dans le fichier Excel.")

    cb = pd.read_excel(xls, sheetnames["codebook"])
    df = pd.read_excel(xls, sheetnames["data"])

    cb = cb.dropna(subset=["Name"])
    cb["Name"] = cb["Name"].astype(str)
    cb["Description"] = cb["Description"].astype(str)
    cb["Value"] = cb["Value"].astype(str)

    # Exclure colonnes techniques dans Data
    cols_keep = []
    for c in df.columns:
        c_str = str(c)
        if c_str in EXCLUDE_COLUMNS:
            continue
        if any(c_str.startswith(p) for p in EXCLUDE_PREFIXES):
            continue
        cols_keep.append(c)
    df = df[cols_keep].copy()

    # Dictionnaires Codebook
    name_to_desc = dict(zip(cb["Name"], cb["Description"]))
    name_to_value = {
        n: (v if v.lower() != "nan" and v != "" else None)
        for n, v in zip(cb["Name"], cb["Value"])
    }

    cb["question_id"] = cb["Name"].apply(get_question_id)

    # question_id -> colonnes pr√©sentes dans Data
    question_to_cols = {}
    for name in cb["Name"]:
        if name in df.columns:
            qid = get_question_id(name)
            if any(qid.startswith(p) for p in EXCLUDE_PREFIXES):
                continue
            question_to_cols.setdefault(qid, []).append(name)

    for k in question_to_cols:
        question_to_cols[k] = sorted(question_to_cols[k])

    return cb, df, name_to_desc, name_to_value, question_to_cols


try:
    codebook, data, name_to_desc, name_to_value, question_to_cols = load_data()
except FileNotFoundError:
    st.error("‚ùå Fichier 'BDD_pso.xlsx' introuvable. Place-le dans le m√™me dossier que 'app.py'.")
    st.stop()
except Exception as e:
    st.error(f"‚ùå Erreur de chargement : {e}")
    st.stop()


def label_with_desc(name: str) -> str:
    """Affiche 'Name ‚Äì Description' s'il existe dans le Codebook."""
    desc = name_to_desc.get(str(name))
    if desc:
        return f"{name} ‚Äì {desc}"
    return str(name)


def clean_categorical_series(s: pd.Series) -> pd.Series:
    """
    Nettoie une s√©rie cat√©gorielle :
    - '0' -> 'Non'
    - '1' -> 'Oui'
    - NaN / vide -> 'Non'
    """
    s = s.astype(str).str.strip()
    return s.replace(
        {"0": "Non", "1": "Oui", "nan": "Non", "": "Non"}
    ).fillna("Non")


def get_numeric_candidates(df: pd.DataFrame):
    """D√©tecte les variables num√©riques pertinentes."""
    numeric_cols = []
    for c in df.columns:
        if c in EXCLUDE_COLUMNS or any(str(c).startswith(p) for p in EXCLUDE_PREFIXES):
            continue
        col = pd.to_numeric(df[c], errors="coerce")
        if col.notna().sum() > len(df) * 0.4 and col.nunique() > 5:
            numeric_cols.append(c)
    return numeric_cols


def is_binary_column(df: pd.DataFrame, col: str) -> bool:
    """Retourne True si la colonne est essentiellement binaire (0/1)."""
    s = df[col].dropna().astype(str).str.strip()
    if s.empty:
        return False
    uniq = set(s.unique())
    return uniq.issubset({"0", "1"})


def compute_question_label(cols):
    """Construit un libell√© commun pour une question multi-r√©ponses."""
    descs = [name_to_desc.get(c, c) for c in cols]
    if not descs:
        return cols[0]
    base = descs[0]
    for d in descs[1:]:
        i = 0
        while i < len(base) and i < len(d) and base[i] == d[i]:
            i += 1
        base = base[:i]
    qpos = base.rfind("?")
    if qpos != -1:
        base = base[: qpos + 1]
    base = base.strip(" :-(")
    if len(base) < 10:
        return descs[0]
    return base


def build_comorbidity_count(df: pd.DataFrame, question_id: str):
    """
    Calcule un score de comorbidit√©s pour un groupe de colonnes
    (question multi-√©l√©ments binaire).
    """
    cols = question_to_cols.get(question_id, [])
    if not cols:
        return None
    sub = df[cols].astype(str)
    present = sub.apply(lambda col: col.notna() & (col.str.strip() != "") & (col.str.strip() != "0"))
    return present.sum(axis=1)


def build_multi_question_groups():
    """
    Construit la liste des groupes multi-r√©ponses :
    - pour les qids dans TARGET_MULTI_QIDS : regroupement par texte de question (avant '?')
    - pour les autres qids : multi si plusieurs colonnes binaires 0/1

    Retourne : (groups, used_cols)
        groups : liste de dict {label, qid, cols}
        used_cols : ensemble de toutes les colonnes appartenant √† un groupe
    """
    groups = []
    used_cols = set()

    # 1. Groupes forc√©s (liste donn√©e par l'utilisatrice)
    for qid, cols in question_to_cols.items():
        if qid not in TARGET_MULTI_QIDS:
            continue
        base_map = {}
        for col in cols:
            desc = name_to_desc.get(col, str(col))
            if "?" in desc:
                base = desc.split("?", 1)[0].strip() + " ?"
            else:
                base = desc.strip()
            base_map.setdefault(base, []).append(col)

        for base, cols_group in base_map.items():
            groups.append(
                {
                    "label": base,
                    "qid": qid,
                    "cols": sorted(cols_group),
                }
            )
            used_cols.update(cols_group)

    # 2. Autres groupes vraiment binaires (0/1)
    for qid, cols in question_to_cols.items():
        if qid in TARGET_MULTI_QIDS:
            continue
        if len(cols) > 1 and all(is_binary_column(data, c) for c in cols):
            label = compute_question_label(cols)
            groups.append(
                {
                    "label": label,
                    "qid": qid,
                    "cols": sorted(cols),
                }
            )
            used_cols.update(cols)

    return groups, used_cols


def build_question_options_for_descriptive():
    """
    Construit les options pour le selectbox descriptif :
    - questions multi-r√©ponses (une par question) -> kind = "multi"
    - autres variables -> kind = "single"
    """
    multi_groups, multi_cols = build_multi_question_groups()
    options = []

    for g in multi_groups:
        options.append(
            {
                "label": g["label"],
                "kind": "multi",
                "id": g["qid"],
                "cols": g["cols"],
            }
        )

    # Variables simples (non utilis√©es dans un groupe multi)
    for col in data.columns:
        if col in multi_cols:
            continue
        desc = name_to_desc.get(col)
        if not desc:
            continue
        options.append(
            {
                "label": desc,
                "kind": "single",
                "id": col,
                "cols": [col],
            }
        )

    options = sorted(options, key=lambda x: x["label"])
    return options


def cramers_v_from_table(ct: pd.DataFrame) -> float:
    """Calcule le V de Cram√©r √† partir d'une table de contingence."""
    chi2, p, dof, _ = stats.chi2_contingency(ct)
    n = ct.values.sum()
    if n == 0:
        return np.nan
    r, k = ct.shape
    return np.sqrt(chi2 / (n * (min(k - 1, r - 1))))


# ---------------------------------------------------------
# HEADER & NAVIGATION
# ---------------------------------------------------------
app_header()

page = st.sidebar.radio(
    "Navigation",
    [
        "üè† Accueil / R√©sum√© global",
        "üìä Analyse descriptive",
        "üß™ Analyse analytique",
        "üß¨ Exploration avanc√©e (clustering)",
        "üìñ Comprendre le psoriasis",
        "üìù Discussion scientifique",
        "üìö Hypoth√®ses & pr√©-traitement",
    ],
)

# ---------------------------------------------------------
# 1. ACCUEIL / R√âSUM√â GLOBAL
# ---------------------------------------------------------
if page == "üè† Accueil / R√©sum√© global":
    st.title("R√©sum√© global de l‚Äôenqu√™te France Psoriasis")

    n = len(data)
    st.subheader("Effectif de l‚Äô√©tude")
    st.markdown(f"- Nombre total de r√©pondants : **{n}**")

    # Sexe
    if "s1" in data.columns:
        st.subheader(label_with_desc("s1"))
        sex_counts = data["s1"].value_counts().rename_axis("Sexe").reset_index(name="Effectif")
        st.dataframe(sex_counts)
        fig_sex = px.pie(sex_counts, values="Effectif", names="Sexe", title="R√©partition par sexe")
        st.plotly_chart(fig_sex, use_container_width=True)

    # √Çge
    if "xs2" in data.columns:
        st.subheader(label_with_desc("xs2"))
        ages = pd.to_numeric(data["xs2"], errors="coerce")
        st.markdown(
            f"- √Çge moyen : **{ages.mean():.1f} ans**  \n"
            f"- M√©diane : **{ages.median():.1f} ans**  \n"
            f"- Intervalle : **{ages.min():.0f} ‚Äì {ages.max():.0f} ans**"
        )
        fig_age = px.histogram(ages, nbins=20, title="Distribution des √¢ges")
        st.plotly_chart(fig_age, use_container_width=True)

    # Habitat
    if "s7c" in data.columns:
        st.subheader(label_with_desc("s7c"))
        habitat = data["s7c"].value_counts().reset_index()
        habitat.columns = ["Habitat", "Effectif"]
        st.dataframe(habitat)
        fig_hab = px.bar(
            habitat,
            x="Habitat",
            y="Effectif",
            title="Type d‚Äôhabitat",
            labels={"Habitat": "", "Effectif": "Effectif"},
        )
        fig_hab.update_layout(xaxis_tickangle=30)
        st.plotly_chart(fig_hab, use_container_width=True)

    # Situation pro / familiale
    for col in ["rs4", "rs5"]:
        if col in data.columns:
            st.subheader(label_with_desc(col))
            ser = data[col].dropna()
            counts = ser.value_counts().reset_index()
            counts.columns = ["Modalit√©", "Effectif"]
            st.dataframe(counts)
            fig = px.bar(counts, x="Modalit√©", y="Effectif", title=label_with_desc(col))
            fig.update_layout(xaxis_tickangle=30)
            st.plotly_chart(fig, use_container_width=True)

    st.markdown("---")
    st.markdown(
        """
        üîç Les autres pages permettent d'explorer :
        - **Analyse descriptive** : distributions, regroupement des questions, carte par r√©gion  
        - **Analyse analytique** : profils, chi¬≤, corr√©lations cat√©gorielles  
        - **Exploration avanc√©e** : clustering des profils de patients  
        - **Comprendre le psoriasis** : rappel clinique & donn√©es fran√ßaises  
        - **Discussion scientifique** : interpr√©tation d√©taill√©e des r√©sultats  
        - **Hypoth√®ses & pr√©-traitement** : transparence m√©thodologique  
        """
    )

# ---------------------------------------------------------
# 2. ANALYSE DESCRIPTIVE
# ---------------------------------------------------------
elif page == "üìä Analyse descriptive":
    st.title("Analyse descriptive d√©taill√©e")

    tab_var, tab_map = st.tabs(["Exploration des questions", "Carte g√©ographique"])

    # ------------------ EXPLORATION DES QUESTIONS ------------------
    with tab_var:
        st.subheader("Exploration par question / item")

        question_options = build_question_options_for_descriptive()
        if not question_options:
            st.warning("Aucune question exploitable d√©tect√©e.")
        else:
            labels = [o["label"] for o in question_options]
            selected_label = st.selectbox(
                "Choisissez une question ou un item √† explorer",
                options=labels,
            )
            choice = next(o for o in question_options if o["label"] == selected_label)

            kind = choice["kind"]
            cols = choice["cols"]

            st.markdown(f"**Question / item s√©lectionn√© :** {selected_label}")
            st.markdown(f"**Nombre d‚Äôitems / r√©ponses possibles :** {len(cols)}")

            graph_type = st.radio(
                "Type de graphique",
                ["Barres", "Camembert", "Histogramme (si question num√©rique)"],
                horizontal=True,
            )

            # ---- CAS SINGLE ----
            if kind == "single":
                var = cols[0]
                serie = data[var]
                numeric_try = pd.to_numeric(serie, errors="coerce")
                is_numeric = (
                        numeric_try.notna().sum() > len(data) * 0.5
                        and numeric_try.nunique() > 5
                )

                if is_numeric:
                    st.markdown("#### Variable num√©rique")
                    st.write(numeric_try.describe())
                    if graph_type == "Histogramme (si question num√©rique)":
                        fig = px.histogram(numeric_try, nbins=20, title=selected_label)
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        fig = px.box(
                            numeric_try,
                            points="outliers",
                            title=selected_label,
                        )
                        st.plotly_chart(fig, use_container_width=True)
                else:
                    st.markdown("#### Variable cat√©gorielle")
                    serie_clean = clean_categorical_series(serie)
                    counts = serie_clean.value_counts().reset_index()
                    counts.columns = ["Modalit√©", "Effectif"]
                    st.dataframe(counts)

                    if graph_type == "Barres":
                        fig = px.bar(
                            counts,
                            x="Modalit√©",
                            y="Effectif",
                            title=selected_label,
                        )
                        fig.update_layout(xaxis_tickangle=30)
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        fig = px.pie(
                            counts,
                            values="Effectif",
                            names="Modalit√©",
                            title=selected_label,
                        )
                        st.plotly_chart(fig, use_container_width=True)

            # ---- CAS MULTI-R√âPONSES ----
            else:
                st.markdown("#### Question √† r√©ponses multiples")

                rows = []
                for col in cols:
                    col_ser = data[col].astype(str).str.strip()
                    present = col_ser.notna() & (col_ser != "") & (col_ser != "0")
                    count = present.sum()
                    if count == 0:
                        continue
                    label = name_to_value.get(col) or name_to_desc.get(col) or col
                    rows.append((label, count))

                if not rows:
                    st.info("Aucune r√©ponse positive pour cette question.")
                else:
                    summary = pd.DataFrame(rows, columns=["R√©ponse", "Effectif"]).sort_values(
                        "Effectif", ascending=False
                    )
                    summary["%"] = summary["Effectif"] / len(data) * 100
                    st.dataframe(summary)

                    if graph_type == "Barres":
                        fig = px.bar(
                            summary,
                            x="R√©ponse",
                            y="Effectif",
                            title=selected_label,
                            labels={"R√©ponse": "", "Effectif": "Effectif"},
                        )
                        fig.update_layout(xaxis_tickangle=30)
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        fig = px.pie(
                            summary,
                            values="Effectif",
                            names="R√©ponse",
                            title=selected_label,
                        )
                        st.plotly_chart(fig, use_container_width=True)

    # ------------------ CARTE G√âOGRAPHIQUE ------------------
    with tab_map:
        st.subheader("Carte g√©ographique ‚Äì r√©partition par grandes r√©gions")

        region_coords = {
            "Ile de France": (48.85, 2.35),
            "√éle de France": (48.85, 2.35),
            "Ouest (Pays de la Loire, Bretagne, Poitou-Charentes)": (47.5, -1.5),
            "M√©diterran√©e (Languedoc-Roussillon, PACA, Corse)": (43.5, 4.8),
            "Mediterranee (Languedoc-Roussillon, PACA, Corse)": (43.5, 4.8),
            "Bassin parisien Ouest (Haute-Normandie, Basse Normandie, Centre)": (48.6, 0.2),
            "Bassin parisien Est (Champagne-Ardenne, Picardie, Bourgogne)": (48.7, 3.5),
            "Sud-Ouest (Aquitaine, Midi-Pyr√©n√©es, Limousin)": (44.5, 0.2),
            "Est (Lorraine, Alsace, Franche-Comt√©)": (48.5, 6.5),
            "Nord (Nord-Pas-de-Calais)": (50.5, 2.7),
            "Sud-Est (Rh√¥ne-Alpes, Auvergne)": (45.5, 4.5),
        }

        if "qs3c" in data.columns:
            region_ser = data["qs3c"].dropna().astype(str).str.strip()
            counts = region_ser.value_counts()
            if counts.empty:
                st.warning("Pas de r√©gions exploitables dans qs3c.")
            else:
                rows = []
                for region, eff in counts.items():
                    coord = region_coords.get(region)
                    if coord is None:
                        reg_norm = (
                            region.replace("√©", "e").replace("√®", "e").replace("√™", "e")
                        )
                        coord = region_coords.get(reg_norm)
                    if coord is None:
                        continue
                    lat, lon = coord
                    rows.append(
                        {"R√©gion": region, "Effectif": eff, "lat": lat, "lon": lon}
                    )

                st.markdown("#### Effectifs par grande r√©gion (qs3c)")
                st.dataframe(
                    counts.rename("Effectif").reset_index().rename(
                        columns={"index": "R√©gion"}
                    )
                )

                if not rows:
                    st.warning(
                        "Impossible d'associer des coordonn√©es aux r√©gions (v√©rifier les libell√©s)."
                    )
                else:
                    df_map = pd.DataFrame(rows)
                    fig_map = px.scatter_mapbox(
                        df_map,
                        lat="lat",
                        lon="lon",
                        size="Effectif",
                        hover_name="R√©gion",
                        hover_data={"Effectif": True},
                        zoom=4.5,
                        height=600,
                    )
                    fig_map.update_layout(
                        mapbox_style="open-street-map",
                        mapbox_center={"lat": 46.5, "lon": 2.5},
                        title="R√©partition des r√©pondants par grandes r√©gions (qs3c)",
                    )
                    st.plotly_chart(fig_map, use_container_width=True)

        elif "qs3" in data.columns:
            st.info(
                "Aucune variable de r√©gion d√©taill√©e (qs3c) trouv√©e. Affichage par IDF / Province via qs3."
            )
            ser = data["qs3"].dropna().astype(str).str.strip()
            counts = ser.value_counts().reset_index()
            counts.columns = ["Zone", "Effectif"]
            st.dataframe(counts)
            fig_bar = px.bar(
                counts,
                x="Zone",
                y="Effectif",
                title="R√©partition IDF / Province (qs3)",
            )
            st.plotly_chart(fig_bar, use_container_width=True)
        else:
            st.warning(
                "Aucune variable g√©ographique exploitable (qs3c ou qs3) n'a √©t√© trouv√©e."
            )

# ---------------------------------------------------------
# 3. ANALYSE ANALYTIQUE
# ---------------------------------------------------------
elif page == "üß™ Analyse analytique":
    st.title("Analyse analytique")

    tab_profils, tab_tests, tab_global = st.tabs(
        ["Profils par question (Oui/Non)", "Tests personnalis√©s", "Analyses globales (cat√©gorielles)"]
    )

    numeric_cols = get_numeric_candidates(data)
    cat_cols = [c for c in data.columns if c not in numeric_cols]

    # ---------------- PROFILS PAR QUESTION MULTI ----------------
    with tab_profils:
        st.subheader("Profils selon une question multi-r√©ponses (Oui / Non)")

        if not numeric_cols:
            st.info("Aucune variable num√©rique pertinente d√©tect√©e.")
        else:
            default_num = "xs2" if "xs2" in numeric_cols else numeric_cols[0]
            num_var = st.selectbox(
                "Variable num√©rique de profil (ex : √¢ge)",
                options=numeric_cols,
                index=numeric_cols.index(default_num),
                format_func=label_with_desc,
            )

            multi_groups, _ = build_multi_question_groups()
            multi_groups = sorted(multi_groups, key=lambda x: x["label"])

            if not multi_groups:
                st.warning(
                    "Aucune question multi-r√©ponses identifi√©e pour cette analyse."
                )
            else:
                labels = [g["label"] for g in multi_groups]
                selected_label = st.selectbox(
                    "Question √† analyser", options=labels
                )
                group = next(g for g in multi_groups if g["label"] == selected_label)

                group_cols = group["cols"]
                st.markdown(f"**Question s√©lectionn√©e :** {selected_label}")
                st.markdown(f"**Nombre d‚Äôitems :** {len(group_cols)}")

                results = []
                num_series = pd.to_numeric(data[num_var], errors="coerce")

                for col in group_cols:
                    col_raw = data[col].astype(str).str.strip()
                    yes_mask = col_raw.notna() & (col_raw != "") & (col_raw != "0")
                    no_mask = ~yes_mask

                    n_yes = yes_mask.sum()
                    n_no = no_mask.sum()

                    if n_yes < 5 or n_no < 5:
                        continue

                    num_yes = num_series[yes_mask]
                    num_no = num_series[no_mask]

                    mean_yes = num_yes.mean()
                    mean_no = num_no.mean()

                    t_stat, p_val = stats.ttest_ind(
                        num_yes.dropna(),
                        num_no.dropna(),
                        equal_var=False,
                        nan_policy="omit",
                    )

                    label = name_to_value.get(col) or name_to_desc.get(col) or col
                    results.append(
                        {
                            "Item": label,
                            "N Oui": n_yes,
                            "N Non": n_no,
                            f"Moyenne {label_with_desc(num_var)} ‚Äì Oui": mean_yes,
                            f"Moyenne {label_with_desc(num_var)} ‚Äì Non": mean_no,
                            "p-value (t-test)": p_val,
                        }
                    )

                if not results:
                    st.info(
                        "Pas assez de donn√©es pour calculer des profils (effectifs trop faibles)."
                    )
                else:
                    df_prof = pd.DataFrame(results).sort_values("p-value (t-test)")
                    st.markdown("#### R√©sultats (class√©s par p-value croissante)")
                    st.dataframe(df_prof)
                    st.markdown(
                        """
                        üßæ **Interpr√©tation**  
                        - Une p-value < 0,05 sugg√®re une diff√©rence significative de la variable choisie
                          (par ex. l'√¢ge) entre les groupes **Oui** et **Non** pour l‚Äôitem consid√©r√©.  
                        - Cela permet d‚Äôidentifier, par exemple, les comorbidit√©s plus fr√©quentes chez les patients plus √¢g√©s.
                        """
                    )

    # ---------------- TESTS PERSONNALIS√âS ----------------
    with tab_tests:
        st.subheader("Tests statistiques personnalis√©s")

        test_type = st.radio(
            "Choisir un test",
            ["Chi¬≤ (2 variables cat√©gorielles)", "Comparaison de moyennes (num√©rique vs 2 groupes)"],
        )

        if test_type == "Chi¬≤ (2 variables cat√©gorielles)":
            if len(cat_cols) < 2:
                st.warning("Pas assez de variables cat√©gorielles.")
            else:
                v1 = st.selectbox("Variable 1", cat_cols, format_func=label_with_desc)
                v2_candidates = [c for c in cat_cols if c != v1]
                v2 = st.selectbox("Variable 2", v2_candidates, format_func=label_with_desc)

                ser1 = clean_categorical_series(data[v1])
                ser2 = clean_categorical_series(data[v2])
                ct = pd.crosstab(ser1, ser2)

                st.markdown("#### Table de contingence")
                st.dataframe(ct)

                chi2, p, dof, expected = stats.chi2_contingency(ct)
                st.markdown("#### R√©sultats du test du Chi¬≤")
                st.write(f"- Chi¬≤ = **{chi2:.3f}**")
                st.write(f"- ddl = **{dof}**")
                st.write(f"- p-value = **{p:.4f}**")

                if p < 0.05:
                    st.success("Association statistiquement significative (p < 0,05).")
                else:
                    st.info("Pas d'association significative mise en √©vidence.")

        else:  # Comparaison de moyennes
            if not numeric_cols or not cat_cols:
                st.warning(
                    "Il faut au moins 1 variable num√©rique et 1 variable cat√©gorielle."
                )
            else:
                num_var = st.selectbox(
                    "Variable num√©rique", numeric_cols, format_func=label_with_desc
                )
                cat_var = st.selectbox(
                    "Variable de groupe (2 modalit√©s)",
                    cat_cols,
                    format_func=label_with_desc,
                )

                ser_num = pd.to_numeric(data[num_var], errors="coerce")
                ser_cat = clean_categorical_series(data[cat_var])
                df_sub = pd.DataFrame({num_var: ser_num, cat_var: ser_cat}).dropna()

                mods = df_sub[cat_var].unique()
                if len(mods) < 2:
                    st.warning("La variable de groupe doit avoir au moins 2 modalit√©s.")
                else:
                    m1 = st.selectbox("Modalit√© 1", mods)
                    m2 = st.selectbox("Modalit√© 2", [m for m in mods if m != m1])

                    g1 = df_sub[df_sub[cat_var] == m1][num_var]
                    g2 = df_sub[df_sub[cat_var] == m2][num_var]

                    st.markdown("#### Statistiques descriptives")
                    stats_df = pd.DataFrame(
                        {
                            "Groupe": [m1, m2],
                            "N": [g1.count(), g2.count()],
                            "Moyenne": [g1.mean(), g2.mean()],
                            "√âcart-type": [g1.std(), g2.std()],
                        }
                    )
                    st.dataframe(stats_df)

                    t, p_val = stats.ttest_ind(
                        g1, g2, equal_var=False, nan_policy="omit"
                    )
                    st.markdown("#### R√©sultats du test t de Student (Welch)")
                    st.write(f"- t = **{t:.3f}**")
                    st.write(f"- p-value = **{p_val:.4f}**")

                    if p_val < 0.05:
                        st.success("Diff√©rence statistiquement significative (p < 0,05).")
                    else:
                        st.info("Pas de diff√©rence significative d√©tect√©e.")

    # ---------------- ANALYSES GLOBALES CATEGORIELLES ----------------
    with tab_global:
        st.subheader("Analyses globales sur les variables cat√©gorielles")

        # Construction de variables synth√©tiques int√©ressantes
        cat_vars = {}

        if "s1" in data.columns:
            cat_vars["Sexe"] = clean_categorical_series(data["s1"])
        if "rs4" in data.columns:
            cat_vars["Situation professionnelle"] = clean_categorical_series(data["rs4"])
        if "rs5" in data.columns:
            cat_vars["Situation familiale"] = clean_categorical_series(data["rs5"])
        if "qs3c" in data.columns:
            cat_vars["R√©gion"] = clean_categorical_series(data["qs3c"])

        # Score de comorbidit√©s rs7aa (ou rs7ab)
        comor = build_comorbidity_count(data, "rs7aa")
        if comor is None:
            comor = build_comorbidity_count(data, "rs7ab")
        if comor is not None:
            cat_vars["‚â•3 comorbidit√©s"] = pd.Series(
                np.where(comor >= 3, "‚â•3 comorbidit√©s", "<3 comorbidit√©s")
            )

        if len(cat_vars) < 2:
            st.info("Pas assez de variables cat√©gorielles pour une analyse globale.")
        else:
            labels = list(cat_vars.keys())

            # Matrice de V de Cram√©r
            m = pd.DataFrame(index=labels, columns=labels, dtype=float)
            for i, l1 in enumerate(labels):
                for j, l2 in enumerate(labels):
                    if i == j:
                        m.loc[l1, l2] = 1.0
                    elif i > j:
                        m.loc[l1, l2] = m.loc[l2, l1]
                    else:
                        s1 = cat_vars[l1]
                        s2 = cat_vars[l2]
                        df_ = pd.DataFrame({l1: s1, l2: s2}).dropna()
                        if df_.empty:
                            v = np.nan
                        else:
                            ct = pd.crosstab(df_[l1], df_[l2])
                            if ct.shape[0] < 2 or ct.shape[1] < 2:
                                v = np.nan
                            else:
                                v = cramers_v_from_table(ct)
                        m.loc[l1, l2] = v

            st.markdown("#### Corr√©lations cat√©gorielles (V de Cram√©r)")
            st.dataframe(m)

            fig_heat = px.imshow(
                m.astype(float),
                text_auto=".2f",
                aspect="auto",
                color_continuous_scale="Reds",
                title="Matrice de V de Cram√©r (variables cat√©gorielles cl√©s)",
            )
            st.plotly_chart(fig_heat, use_container_width=True)

            st.markdown(
                """
                üîé **Lecture rapide**  
                - V de Cram√©r proche de 0 ‚Üí faible association.  
                - V de Cram√©r > 0,2 ‚Üí association mod√©r√©e potentiellement int√©ressante.  

                Cela permet par exemple de voir si la situation professionnelle ou familiale
                est li√©e au fait d‚Äôavoir ‚â•3 comorbidit√©s ou √† la r√©partition g√©ographique.
                """
            )

            # Quelques tests Chi¬≤ automatiques utiles pour la discussion
            st.markdown("#### Quelques tests du Chi¬≤ pr√©-s√©lectionn√©s")

            tests_pairs = [
                ("Sexe", "‚â•3 comorbidit√©s"),
                ("Situation professionnelle", "‚â•3 comorbidit√©s"),
                ("Situation familiale", "‚â•3 comorbidit√©s"),
                ("R√©gion", "‚â•3 comorbidit√©s"),
            ]

            for v1, v2 in tests_pairs:
                if v1 not in cat_vars or v2 not in cat_vars:
                    continue
                st.markdown(f"**{v1} √ó {v2}**")
                s1 = cat_vars[v1]
                s2 = cat_vars[v2]
                df_ = pd.DataFrame({v1: s1, v2: s2}).dropna()
                if df_.empty:
                    st.write("Donn√©es insuffisantes.")
                    continue
                ct = pd.crosstab(df_[v1], df_[v2])
                st.dataframe(ct)
                if ct.shape[0] < 2 or ct.shape[1] < 2:
                    st.write("Pas assez de modalit√©s pour un Chi¬≤ interpr√©table.")
                    st.markdown("---")
                    continue
                chi2, p, dof, _ = stats.chi2_contingency(ct)
                st.write(f"- Chi¬≤ = **{chi2:.2f}**, ddl = **{dof}**, p-value = **{p:.4f}**")
                st.markdown("---")

# ---------------------------------------------------------
# 4. CLUSTERING
# ---------------------------------------------------------
elif page == "üß¨ Exploration avanc√©e (clustering)":
    st.title("Exploration avanc√©e ‚Äì Clustering des profils de patients")

    st.markdown(
        """
        L‚Äôobjectif est d‚Äôidentifier des **profils de patients** √† partir de deux dimensions :
        - l‚Äô**√¢ge** (xs2)  
        - le **nombre de comorbidit√©s chroniques** d√©clar√©es (question des maladies associ√©es)

        On applique un algorithme de **K-means** pour regrouper les patients en clusters.
        """
    )

    question_for_comor = "rs7aa" if "rs7aa" in question_to_cols else "rs7ab"
    comorbid_count = build_comorbidity_count(data, question_for_comor)

    if comorbid_count is None:
        st.warning(
            "Impossible de calculer le score de comorbidit√©s (groupe rs7aa/rs7ab absent)."
        )
    elif "xs2" not in data.columns:
        st.warning("La variable d'√¢ge 'xs2' est requise pour le clustering.")
    else:
        ages = pd.to_numeric(data["xs2"], errors="coerce")
        df_cluster = pd.DataFrame({"age": ages, "nb_comorbidites": comorbid_count}).dropna()

        st.markdown(f"- Nombre de patients utilisables pour le clustering : **{len(df_cluster)}**")

        if len(df_cluster) < 20:
            st.warning("√âchantillon trop petit pour un clustering informatif (> 20 recommand√©).")
        else:
            k = st.slider("Nombre de clusters (K)", min_value=2, max_value=5, value=3)

            km = KMeans(n_clusters=k, random_state=42, n_init="auto")
            labels = km.fit_predict(df_cluster)
            df_cluster["cluster"] = labels.astype(str)

            fig = px.scatter(
                df_cluster,
                x="age",
                y="nb_comorbidites",
                color="cluster",
                title="Clusters de patients (√¢ge vs nombre de comorbidit√©s)",
                labels={"age": "√Çge", "nb_comorbidites": "Nombre de comorbidit√©s chroniques"},
            )
            st.plotly_chart(fig, use_container_width=True)

            st.markdown("### R√©sum√© statistique par cluster")
            summary = (
                df_cluster.groupby("cluster")
                .agg(
                    N=("age", "count"),
                    age_moy=("age", "mean"),
                    comor_moy=("nb_comorbidites", "mean"),
                )
                .reset_index()
            )
            st.dataframe(summary)

            st.markdown(
                """
                üîç **Interpr√©tation possible des clusters :**
                - Un cluster peut regrouper des patients **plus jeunes avec peu ou pas de comorbidit√©s**.  
                - Un autre cluster peut correspondre √† des patients **plus √¢g√©s, tr√®s comorbides**, 
                  potentiellement √† plus haut risque cardiovasculaire ou m√©tabolique.  
                - Un cluster interm√©diaire peut repr√©senter des profils mixtes.  

                Ces profils peuvent aider √† :
                - cibler des messages de **pr√©vention** (poids, tabac, diab√®te, activit√© physique),  
                - prioriser certains patients pour des **√©valuations sp√©cialis√©es** (cardio, rhumato, psy),  
                - soutenir des arguments de **sant√© publique** sur la nature syst√©mique du psoriasis.
                """
            )

# ---------------------------------------------------------
# 5. COMPRENDRE LE PSORIASIS
# ---------------------------------------------------------
elif page == "üìñ Comprendre le psoriasis":
    st.title("Comprendre le psoriasis")

    st.markdown(
        """
        Le **psoriasis** est une maladie inflammatoire chronique de la peau, √† m√©diation immune, 
        qui touche la peau, parfois les ongles et les articulations, et s‚Äôaccompagne fr√©quemment 
        de comorbidit√©s m√©taboliques et cardiovasculaires.

        ---
        ### 1. Physiopathologie (en bref)

        - Activation de l‚Äôaxe **IL-23 / IL-17 / TNFŒ±** et des lymphocytes T.  
        - Hyperprolif√©ration des k√©ratinocytes ‚Üí plaques √©ryth√©mato-squameuses bien limit√©es.  
        - Inflammation syst√©mique de bas grade impliqu√©e dans le risque cardio-m√©tabolique.  

        ---
        ### 2. Formes cliniques principales

        - **Psoriasis en plaques** (forme la plus fr√©quente).  
        - Psoriasis du **cuir chevelu**.  
        - Atteinte **ungu√©ale** (ongles stri√©s, d√©press√©s, onycholyse).  
        - Psoriasis **palmo-plantaire**.  
        - Psoriasis **en gouttes**.  
        - Formes s√©v√®res : **pustuleux g√©n√©ralis√©**, **√©rythrodermie psoriasique**.  
        - **Rhumatisme psoriasique** (atteinte articulaire p√©riph√©rique ou axiale).

        ---
        ### 3. Comorbidit√©s associ√©es

        Le psoriasis est reconnu comme une **maladie syst√©mique** :

        - **Syndrome m√©tabolique** : ob√©sit√©, diab√®te de type 2, dyslipid√©mies.  
        - **Hypertension art√©rielle**, maladie coronarienne, AVC.  
        - **Rhumatisme psoriasique** (douleurs, raideurs, dactylites, enth√©sites).  
        - **Troubles anxieux et d√©pressifs**, alt√©ration de l‚Äôestime de soi.  
        - Autres associations possibles : NAFLD, MICI, uv√©ites.

        ---
        ### 4. Impact sur la qualit√© de vie

        - G√™ne esth√©tique, stigmatisation, sentiment de rejet.  
        - R√©percussions sur la vie professionnelle, sociale, affective et intime.  
        - Peur des pouss√©es, incompr√©hension de l‚Äôentourage (psoriasis non contagieux mais souvent per√ßu comme tel).

        ---
        ### 5. Options th√©rapeutiques (tr√®s synth√©tique)

        - **Topiques** : dermocortico√Ødes, analogues de la vitamine D, combinaisons.  
        - **Phototh√©rapie** (UVB, PUVA).  
        - **Syst√©miques conventionnels** : m√©thotrexate, ciclosporine, acitr√©tine, apremilast.  
        - **Bioth√©rapies / mol√©cules cibl√©es** : anti-TNFŒ±, anti-IL-17, anti-IL-12/23, anti-IL-23, inhibiteurs de JAK, etc.  

        Le choix th√©rapeutique int√®gre :
        - la s√©v√©rit√© cutan√©e et articulaire,  
        - les comorbidit√©s,  
        - les contraintes de suivi,  
        - le projet de vie du patient.

        ---
        Cette enqu√™te France Psoriasis permet de mettre ces √©l√©ments en perspective √† partir 
        du **v√©cu r√©el** des patients en France.
        """
    )

# ---------------------------------------------------------
# 6. DISCUSSION SCIENTIFIQUE
# ---------------------------------------------------------
elif page == "üìù Discussion scientifique":
    st.title("Discussion scientifique ‚Äì Interpr√©tation des r√©sultats de l‚Äôenqu√™te")

    n = len(data)
    ages = pd.to_numeric(data.get("xs2", pd.Series(dtype=float)), errors="coerce")
    age_mean = ages.mean()
    age_med = ages.median()

    sex_counts = data.get("s1", pd.Series(dtype=object)).value_counts()
    n_f = int(sex_counts.get("Une femme", 0))
    n_h = int(sex_counts.get("Un homme", 0))

    # Comorbidit√©s (rs7aa si dispo sinon rs7ab)
    question_for_comor = "rs7aa" if "rs7aa" in question_to_cols else "rs7ab"
    comorbid_count = build_comorbidity_count(data, question_for_comor)

    top_comor = None
    age_by_comor = []
    if comorbid_count is not None:
        cols = question_to_cols.get(question_for_comor, [])
        rows = []
        for col in cols:
            ser = data[col].astype(str).str.strip()
            present = ser.notna() & (ser != "") & (ser != "0")
            count = present.sum()
            if count == 0:
                continue
            label = name_to_value.get(col) or name_to_desc.get(col) or col
            rows.append((label, count))

            ages_series = pd.to_numeric(data.get("xs2", pd.Series(dtype=float)), errors="coerce")
            age_yes = ages_series[present]
            age_no = ages_series[~present]
            if age_yes.count() >= 5 and age_no.count() >= 5:
                t_stat, p_val = stats.ttest_ind(
                    age_yes.dropna(),
                    age_no.dropna(),
                    equal_var=False,
                    nan_policy="omit",
                )
                age_by_comor.append(
                    {
                        "Comorbidit√©": label,
                        "√Çge moyen Oui": age_yes.mean(),
                        "√Çge moyen Non": age_no.mean(),
                        "p-value": p_val,
                    }
                )

        if rows:
            df_comor = pd.DataFrame(rows, columns=["Comorbidit√©", "Effectif"])
            df_comor["%"] = df_comor["Effectif"] / n * 100
            top_comor = df_comor.sort_values("Effectif", ascending=False).head(8)

    st.markdown(
        f"""
        ### 1. Profil g√©n√©ral des r√©pondants

        L‚Äôenqu√™te France Psoriasis inclut **{n}** r√©pondants.  
        L‚Äô√¢ge moyen est d‚Äôenviron **{age_mean:.1f} ans** (m√©diane ~ **{age_med:.1f} ans**), 
        ce qui correspond √† une population adulte, avec une proportion importante de patients 
        d‚Äô√¢ge m√ªr, susceptibles de cumuler plusieurs facteurs de risque cardiovasculaire.

        La r√©partition par sexe montre :
        - **{n_f} femmes**
        - **{n_h} hommes**

        Cette l√©g√®re sur-repr√©sentation f√©minine est classique dans les enqu√™tes associatives 
        (engagement plus fr√©quent des femmes dans les d√©marches de sant√©).
        """
    )

    if top_comor is not None:
        st.markdown("### 2. Comorbidit√©s les plus fr√©quemment rapport√©es")
        st.dataframe(top_comor)

        st.markdown(
            """
            Ces r√©sultats objectivent une forte pr√©valence de comorbidit√©s dans la population psoriasique,
            en particulier des composantes **m√©taboliques** et **rhumatologiques**.

            En pratique clinique, cela renforce :
            - la n√©cessit√© d‚Äôun **d√©pistage structur√©** (poids, TA, bilan glyc√©mique et lipidique) 
              lors des consultations de dermatologie ;  
            - l‚Äôimportance de **questionner syst√©matiquement** les patients sur les douleurs articulaires 
              et les sympt√¥mes anxio-d√©pressifs ;  
            - le besoin d‚Äôune **coordination √©troite** avec le m√©decin traitant, les cardiologues, 
              endocrinologues et rhumatologues.
            """
        )

    if age_by_comor:
        df_age_comor = pd.DataFrame(age_by_comor).sort_values("p-value")
        st.markdown("### 3. Lien entre √¢ge et comorbidit√©s")
        st.dataframe(df_age_comor)

        st.markdown(
            """
            Dans plusieurs comorbidit√©s, l‚Äô√¢ge moyen des patients atteints appara√Æt plus √©lev√© 
            que celui des patients non atteints.  
            Sans pr√©tendre √† une analyse causale, ces r√©sultats s‚Äôinscrivent dans le concept de 
            **¬´ marche psoriasique ¬ª**, o√π l‚Äôinflammation chronique de bas grade, associ√©e aux 
            facteurs de style de vie, conduit progressivement √† :

            - une augmentation de la masse grasse visc√©rale,  
            - une r√©sistance √† l‚Äôinsuline,  
            - une dyslipid√©mie,  
            - puis √† la survenue d‚Äô√©v√©nements cardiovasculaires majeurs.
            """
        )

    # Exemple bivari√© suppl√©mentaire : sexe √ó comorbidit√©s
    if comorbid_count is not None and "s1" in data.columns:
        st.markdown("### 4. Exemple d‚Äôanalyse bivari√©e : sexe et pr√©sence de comorbidit√©s")

        has_comor = comorbid_count > 0
        sex = data["s1"].fillna("Non renseign√©")
        ct = pd.crosstab(sex, has_comor)
        chi2, p, dof, _ = stats.chi2_contingency(ct)

        st.markdown("Tableau crois√© : sexe √ó au moins une comorbidit√©")
        st.dataframe(ct)

        st.markdown(f"- Chi¬≤ = **{chi2:.2f}**, p-value = **{p:.4f}**")

        st.markdown(
            """
            Ce type d‚Äôanalyse permet de v√©rifier si les femmes rapportent plus souvent les comorbidit√©s
            que les hommes (ou l‚Äôinverse), ce qui peut traduire √† la fois des diff√©rences biologiques,
            mais aussi des **diff√©rences de recours aux soins** ou de perception de la maladie.
            """
        )

    # Exemple bivari√© : r√©gion (si dispo) √ó pr√©sence de comorbidit√©s
    if comorbid_count is not None and "qs3c" in data.columns:
        st.markdown("### 5. Exemple d‚Äôanalyse bivari√©e : r√©gion et pr√©sence de comorbidit√©s")

        has_comor = comorbid_count > 0
        region = data["qs3c"].fillna("Non renseign√©")
        ct_reg = pd.crosstab(region, has_comor)
        chi2_reg, p_reg, dof_reg, _ = stats.chi2_contingency(ct_reg)

        st.markdown("Tableau crois√© : r√©gion √ó au moins une comorbidit√©")
        st.dataframe(ct_reg)

        st.markdown(f"- Chi¬≤ = **{chi2_reg:.2f}**, p-value = **{p_reg:.4f}**")

        st.markdown(
            """
            M√™me si les effectifs par r√©gion sont parfois limit√©s, ce type d‚Äôanalyse peut faire √©merger
            des **hypoth√®ses r√©gionales** (diff√©rences socio-√©conomiques, acc√®s diff√©renci√© aux soins 
            sp√©cialis√©s, densit√© de dermatologues, etc.) qui m√©riteraient d‚Äô√™tre explor√©es dans 
            des travaux d√©di√©s.
            """
        )

    st.markdown(
        """
        ---
        ### 6. Messages cl√©s et recommandations

        1. **D√©pistage syst√©matique des comorbidit√©s**  
           - Mesure de l‚ÄôIMC, de la tension art√©rielle, bilan glucido-lipidique.  
           - Recherche de sympt√¥mes √©vocateurs de rhumatisme psoriasique et de troubles anxio-d√©pressifs.  

        2. **Prise en charge multidisciplinaire structur√©e**  
           - Coordination dermatologue‚Äìm√©decin traitant‚Äìrhumatologue‚Äìcardiologue‚Äìpsychiatre/psychologue.  
           - R√¥le central des √©quipes hospitali√®res et des r√©seaux de soins pour les formes s√©v√®res.  

        3. **Personnalisation des objectifs th√©rapeutiques**  
           - Intensification des traitements (bioth√©rapies, petites mol√©cules cibl√©es) chez les patients 
             comorbides ou √† haut risque cardio-m√©tabolique.  
           - Prise en compte de l‚Äô√¢ge, du statut professionnel, des projets de grossesse, des pr√©f√©rences 
             du patient dans le choix des traitements.  

        4. **R√¥le des associations de patients**  
           - Les donn√©es issues de France Psoriasis montrent la capacit√© de l‚Äôassociation √† documenter 
             le v√©cu r√©el des patients et √† produire des donn√©es **utiles √† la sant√© publique**.  
           - Ces r√©sultats peuvent nourrir des argumentaires pour am√©liorer l‚Äô**acc√®s aux soins** 
             (consultations sp√©cialis√©es, ETP, psychologues, etc.).

        ---
        ### 7. Perspectives de publication

        Les analyses propos√©es (descriptif d√©taill√©, profils par comorbidit√©s, exemples de tests bivari√©s)
        permettent de structurer un article du type :

        > **¬´ Profil clinique, comorbidit√©s et parcours de soins des patients atteints de psoriasis en France :
        r√©sultats de l‚Äôenqu√™te France Psoriasis ¬ª**

        L‚Äôapplication peut √™tre utilis√©e pour g√©n√©rer directement :
        - le tableau des caract√©ristiques g√©n√©rales,  
        - le tableau des comorbidit√©s,  
        - des tableaux de tests bivari√©s (√¢ge / sexe / r√©gion / comorbidit√©s),  
        qui serviront de base √† la r√©daction.
        """
    )

# ---------------------------------------------------------
# 7. HYPOTH√àSES & PR√â-TRAITEMENT
# ---------------------------------------------------------
elif page == "üìö Hypoth√®ses & pr√©-traitement":
    st.title("Hypoth√®ses de pr√©-traitement et limites m√©thodologiques")

    st.markdown(
        """
        Cette section d√©crit de fa√ßon transparente les **choix de pr√©-traitement** et les **hypoth√®ses**
        utilis√©s dans cette application pour analyser la base de donn√©es France Psoriasis.

        ### 1. Structure de la base

        - Onglet **`Codebook`** : dictionnaire des questions  
          - `Name` : identifiant de variable  
          - `Description` : texte de la question / de l‚Äôitem  
          - `Value` : libell√©s des r√©ponses possibles (pour les questions multi-√©l√©ments)  
        - Onglet **`Data`** : r√©ponses individuelles des participants.

        ### 2. Regroupement au niveau des questions

        - Les variables de l‚Äôonglet Data sont initialement cod√©es comme `Name`  
          (ex : `b6:1`, `b6:2`, `rs7ab_1:1`, etc.).  
        - Un identifiant de question est reconstruit par la fonction `get_question_id` :  
          - on supprime d‚Äôabord ce qui suit `:` (‚Üí `b6:1` devient `b6`, `rs7ab_1:17` devient `rs7ab_1`),  
          - puis, s‚Äôil existe, ce qui suit `_` (‚Üí `rs7ab_1` devient `rs7ab`).  
        - Toutes les colonnes partageant le m√™me identifiant de question sont regroup√©es dans 
          `question_to_cols[question_id]`.  

        - Pour les identifiants list√©s par l‚Äôenqu√™te (par ex. `rs7aa`, `rs7ab`, `rs7ba`, `rs7bb`, `a3`, `b5`, `b6`,
          `b10`, `recrs7aa`, `recrs7`, `recrs7a`), les questions sont **explicitement regroup√©es** par texte :
          - on extrait la partie de la Description situ√©e avant le `?`  
          - toutes les modalit√©s associ√©es (diab√®te, HTA, asthme, etc.) sont rassembl√©es sous la m√™me question.  

        - Si une question comporte plusieurs colonnes binaires **0/1**, elle est trait√©e comme 
          **question √† r√©ponses multiples** (une seule entr√©e dans le selectbox, agr√©gation des items).  
        - Les questions ordinales de type **Likert** (Tout √† fait d‚Äôaccord, etc.) sont laiss√©es 
          **item par item**.

        ### 3. Colonnes exclues des analyses

        - Pr√©fixes techniques : `alerte`, `alertes`, `CW`, `CW_`, `CW_token`, `CW_status`,  
          `CW_firstdate`, `CW_firsttime`, `CW_finishdate`, `CW_finishtime`.  
        - Colonnes : `nbj`, `vague`, `fincontact`, `mode`, `revi`.  

        ### 4. Gestion des valeurs manquantes et aberrantes

        - Variables num√©riques :
          - tentative de conversion (`pd.to_numeric`),  
          - exclusion des variables avec trop peu de valeurs num√©riques ou faible variabilit√©,  
          - analyses r√©alis√©es uniquement sur les lignes non manquantes (pas d‚Äôimputation avanc√©e).  
        - Variables cat√©gorielles :
          - `0`, vide ou `NaN` ‚Üí **¬´ Non ¬ª**,  
          - `1` ‚Üí **¬´ Oui ¬ª**,  
          - autres modalit√©s textuelles conserv√©es.

        ### 5. Score de comorbidit√©s

        - Pour les questions de type ¬´ maladies associ√©es ¬ª (`rs7aa` / `rs7ab`),  
          un score de comorbidit√©s global est calcul√© :  
          - chaque item > 0 (ou non vide) = comorbidit√© pr√©sente,  
          - le score est la **somme** des comorbidit√©s pr√©sentes.  

        ### 6. Tests statistiques

        - **Chi¬≤** : association entre deux variables cat√©gorielles.  
        - **t-test de Student (Welch)** : comparaison de moyennes entre deux groupes ind√©pendants.  
        - **V de Cram√©r** : mesure d‚Äôintensit√© de l‚Äôassociation entre deux variables cat√©gorielles 
          (matrice pr√©sent√©e dans l‚Äôonglet *Analyses globales*).  
        - Seuil de significativit√© indicatif : **p < 0,05**, sans correction pour comparaisons multiples 
          (√† discuter dans le manuscrit).

        ### 7. Clustering

        - Clustering K-means r√©alis√© sur deux dimensions :
          - √¢ge (xs2)  
          - nombre de comorbidit√©s chroniques (score rs7aa/rs7ab)  
        - Standardisation non appliqu√©e (ordre de grandeur comparable entre les deux variables).  
        - Interpr√©tation descriptive, sans pr√©tention √† d√©finir des sous-types ¬´ d√©finitifs ¬ª de psoriasis.

        ### 8. Limites

        - √âchantillon volontaire, non probabiliste ‚Üí possible biais de s√©lection.  
        - Analyses transversales (pas de suivi longitudinal).  
        - Qualit√© des donn√©es d√©pendante du remplissage et de la compr√©hension du questionnaire.  
        - Pas d‚Äôajustement multivari√© syst√©matique dans cette version (mais possible dans une version future).

        ### 9. Pistes d‚Äô√©volution

        - Int√©gration de mod√®les multivari√©s (r√©gressions logistiques, mod√®les lin√©aires).  
        - Meilleure exploitation des donn√©es de s√©v√©rit√© cutan√©e et articulaire (PASI, DLQI, scores de douleur).  
        - Exports automatiques des tableaux au format Excel / LaTeX pour faciliter la r√©daction de publications.  
        - D√©veloppement de modules de simulation (par ex. impact d‚Äôune r√©duction de l‚ÄôIMC sur le risque
          cardiovasculaire dans une population psoriasique).

        ---
        Ces hypoth√®ses et choix m√©thodologiques peuvent √™tre repris tels quels dans la 
        **section Mat√©riels et M√©thodes** de l‚Äôarticle.
        """
    )
